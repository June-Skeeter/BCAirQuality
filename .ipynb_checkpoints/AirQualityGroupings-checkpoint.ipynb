{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script downloads hourly airquality data from DATABC's ftp server and agregates it by month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading TEMP_MEAN\n",
      "2019\n",
      "2020\n",
      "EMS_ID\n",
      "0250009    30418\n",
      "0260011    30418\n",
      "0260012    12874\n",
      "0310162    12874\n",
      "0310177    12874\n",
      "           ...  \n",
      "M102038    17544\n",
      "M107004    30418\n",
      "M109914    29734\n",
      "M111073    30418\n",
      "M114009    30090\n",
      "Name: STATION_NAME, Length: 95, dtype: int64\n",
      "Completed TEMP : there are  95  stations available to analyze.\n",
      "\n",
      "Downloading PM25\n",
      "2019\n",
      "2020\n",
      "EMS_ID\n",
      "0310162    30418\n",
      "0310177    30418\n",
      "0310179    30418\n",
      "0450307    30418\n",
      "0500886     3899\n",
      "           ...  \n",
      "E321711    15286\n",
      "E326405     5570\n",
      "E327591     3355\n",
      "E327924     2307\n",
      "M107004    30418\n",
      "Name: STATION_NAME, Length: 73, dtype: int64\n",
      "Completed PM25 : there are  72  stations available to analyze.\n",
      "\n",
      "Downloading O3\n",
      "2019\n",
      "2020\n",
      "EMS_ID\n",
      "0310162    30418\n",
      "0310174    30418\n",
      "0310177    30418\n",
      "0310179    30418\n",
      "0450307    30418\n",
      "0500886     3899\n",
      "0550502    30418\n",
      "0605008    30418\n",
      "0770708    30418\n",
      "E206270    30418\n",
      "E206271    30418\n",
      "E207417    30418\n",
      "E207418    30418\n",
      "E207723    30418\n",
      "E208096    11651\n",
      "E209177    30418\n",
      "E209178    30418\n",
      "E220891    30418\n",
      "E223615    30418\n",
      "E223756    30418\n",
      "E227431    30418\n",
      "E229797    30418\n",
      "E231866    30418\n",
      "E232244    30418\n",
      "E232245    30418\n",
      "E232246    30418\n",
      "E238212    30418\n",
      "E240337    30416\n",
      "E242892    30418\n",
      "E249492    30418\n",
      "E262137     4859\n",
      "E283549    30418\n",
      "E285829    30418\n",
      "E286369    30418\n",
      "E289309    30418\n",
      "E293810    30418\n",
      "E295892    30418\n",
      "E299830    30418\n",
      "E300350    30418\n",
      "E302130    30418\n",
      "E304570    30418\n",
      "E308566    30418\n",
      "E311128    30418\n",
      "E312331    30418\n",
      "E313510    30418\n",
      "E315110    30418\n",
      "E316370    30418\n",
      "E317850    24586\n",
      "E320071    13098\n",
      "E326405     5570\n",
      "E327591     3355\n",
      "E328532      624\n",
      "Name: STATION_NAME, dtype: int64\n",
      "Completed O3 : there are  52  stations available to analyze.\n",
      "\n",
      "Downloading CO\n",
      "2019\n",
      "2020\n",
      "EMS_ID\n",
      "0310162    30418\n",
      "0310174    30418\n",
      "0310177    30418\n",
      "0310179    30418\n",
      "0500886     3899\n",
      "E206271    30418\n",
      "E207417    30418\n",
      "E207418    30418\n",
      "E209177    30418\n",
      "E209178    30418\n",
      "E220891    30418\n",
      "E223756    30418\n",
      "E231866    30418\n",
      "E232245    30418\n",
      "E232246    30418\n",
      "E238212    17544\n",
      "E242892    30418\n",
      "E275843    17544\n",
      "E283549    30418\n",
      "E289309    30418\n",
      "E309527    30418\n",
      "E316370    30418\n",
      "E317850    24586\n",
      "Name: STATION_NAME, dtype: int64\n",
      "Completed CO : there are  23  stations available to analyze.\n",
      "\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request \n",
    "import os\n",
    "\n",
    "\n",
    "Host = \"ftp://ftp.env.gov.bc.ca/\"\n",
    "\n",
    "\n",
    "## 2009 is the first year the data is aggregated yearly - The 2021 data is not available yet\n",
    "Last_Year = 2020\n",
    "# Years = [str(x) for x in range(2010,Last_Year+1)]\n",
    "Years = [str(x) for x in range(2010,Last_Year+1)]\n",
    "## The gas/particulate data available \n",
    "Species = [\"TEMP_MEAN\",\"PM25\",\"O3\",\"CO\"] # Other Species Avaialble - \"H2S\",\"NO\",\"NO2\",\"PM10\",\"SO2\",\"TRS\"\n",
    "\n",
    "def ReadFile(Data = None):\n",
    "    if Data is None:\n",
    "        Data = pd.read_csv('Temp.csv',parse_dates={'datetime':[0]},index_col=['datetime'],\n",
    "                              dtype={\"DATE_PST\":str,\"STATION_NAME\":str,\"EMS_ID\":str,\"PARAMETER\":str,\n",
    "                                     \"INSTRUMENT\":str,\"RAW_VALUE\":float,\"UNIT\":str,\"ROUNDED_VALUE\":float},encoding='ISO-8859-1')\n",
    "        Data['Month']=Data.index.month\n",
    "        Data['Year']=Data.index.year\n",
    "    else:\n",
    "        NewData = pd.read_csv('Temp.csv',parse_dates={'datetime':[0]},index_col=['datetime'],\n",
    "                              dtype={\"DATE_PST\":str,\"STATION_NAME\":str,\"EMS_ID\":str,\"PARAMETER\":str,\n",
    "                                     \"INSTRUMENT\":str,\"RAW_VALUE\":float,\"UNIT\":str,\"ROUNDED_VALUE\":float},encoding='ISO-8859-1')\n",
    "        NewData['Month']=NewData.index.month\n",
    "        NewData['Year']=NewData.index.year\n",
    "        Data = Data.append(NewData)\n",
    "    return(Data)\n",
    "\n",
    "for species in Species:\n",
    "    print('Downloading '+species)\n",
    "    Data = None    \n",
    "    for year in Years:\n",
    "#         print(year)\n",
    "        Data_Path = \"pub/outgoing/AIR/AnnualSummary/\"\n",
    "        path = Host+Data_Path+year+'/'+species+'.csv'\n",
    "        urllib.request.urlretrieve(path, 'Temp.csv')\n",
    "        Data = ReadFile(Data)\n",
    "#     if Last_Year\n",
    "    \n",
    "    Data_Path = 'pub/outgoing/AIR/Hourly_Raw_Air_Data/Year_to_Date/'\n",
    "    path = Host+Data_Path+species+'.csv'\n",
    "    urllib.request.urlretrieve(path, 'Temp.csv')\n",
    "    Data = ReadFile(Data)\n",
    "        \n",
    "    # Agregate data by year and write to a file\n",
    "    if species == 'TEMP_MEAN':\n",
    "        species = 'TEMP'\n",
    "    \n",
    "    AggData = Data.groupby(['EMS_ID','Year']).agg({'RAW_VALUE':'mean'})\n",
    "    Yearly = AggData.unstack()['RAW_VALUE'].to_csv('Data/'+species+'_Yearly_Averages.csv')\n",
    "    \n",
    "    Data['Year_Month'] = Data['Year']*100+Data['Month']\n",
    "    AggData = Data.groupby(['EMS_ID','Year_Month']).agg({'RAW_VALUE':'mean'})\n",
    "    AggData.unstack()['RAW_VALUE'].to_csv('Data/'+species+'_MonthlyAverages.csv')\n",
    "    \n",
    "       \n",
    "    Summer = Data.loc[((Data['Month']>=6)&(Data['Month']<=9))].copy()\n",
    "    AggData = Summer.groupby(['EMS_ID','Year']).agg({'RAW_VALUE':'mean'})\n",
    "    AggData.unstack()['RAW_VALUE'].to_csv('Data/'+species+'_SummerAverages.csv')\n",
    "    \n",
    "#     Last_Year = Data.loc[Data.index.year>=2021]\n",
    "\n",
    "#     Last_Year=Last_Year.groupby([Last_Year.index,Last_Year.EMS_ID]).mean().unstack()['RAW_VALUE']\n",
    "    \n",
    "    \n",
    "    Daily=Data.groupby([Data.index,Data.EMS_ID]).mean().unstack()['RAW_VALUE']\n",
    "\n",
    "#     print(Daily)\n",
    "\n",
    "    Daily.loc[Daily.index.year>=2020].to_csv('Data/'+species+'_Daily_Averages_2020_Onward.csv')\n",
    "    \n",
    "    print('Completed '+species,': there are ',AggData.unstack().shape[0],' stations available to analyze.')\n",
    "    print()\n",
    "os.remove('Temp.csv')\n",
    "print('Done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sites = pd.read_csv('ftp://ftp.env.gov.bc.ca/pub/outgoing/AIR/Air_Monitoring_Stations/bc_air_monitoring_stations.csv')\n",
    "Sites.to_csv('MonitoringStations.csv')\n",
    "Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.read_csv('PM25.csv')\n",
    "\n",
    "DF['STATION_NAME'].unique()\n",
    "\n",
    "# # Last_Year = Data.loc[Data.index.year>=2021]\n",
    "\n",
    "# Daily=Data.groupby([Data.index,Data.EMS_ID]).mean().unstack()['RAW_VALUE']\n",
    "\n",
    "# print(Daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "with open('Temp.csv', 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(100000))\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
