{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script downloads hourly airquality data from DATABC's ftp server and agregates it by month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading TEMP_MEAN\n",
      "2020\n",
      "Completed TEMP_MEAN : there are  57  stations available to analyze.\n",
      "\n",
      "Downloading PM25\n",
      "2020\n",
      "Completed PM25 : there are  61  stations available to analyze.\n",
      "\n",
      "Downloading O3\n",
      "2020\n",
      "Completed O3 : there are  46  stations available to analyze.\n",
      "\n",
      "Downloading CO\n",
      "2020\n",
      "Completed CO : there are  20  stations available to analyze.\n",
      "\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request \n",
    "import os\n",
    "\n",
    "\n",
    "Host = \"ftp://ftp.env.gov.bc.ca/\"\n",
    "\n",
    "\n",
    "## 2009 is the first year the data is aggregated yearly - The 2021 data is not available yet\n",
    "Last_Year = 2020\n",
    "Years = [str(x) for x in range(2020,Last_Year+1)]\n",
    "## The gas/particulate data available \n",
    "Species = [\"TEMP_MEAN\",\"PM25\",\"O3\",\"CO\"] # Other Species Avaialble - \"H2S\",\"NO\",\"NO2\",\"PM10\",\"SO2\",\"TRS\"\n",
    "\n",
    "def ReadFile(Data = None):\n",
    "    if Data is None:\n",
    "        Data = pd.read_csv('Temp.csv',parse_dates={'datetime':[0]},index_col=['datetime'],\n",
    "                              dtype={\"DATE_PST\":str,\"STATION_NAME\":str,\"EMS_ID\":str,\"PARAMETER\":str,\n",
    "                                     \"INSTRUMENT\":str,\"RAW_VALUE\":float,\"UNIT\":str,\"ROUNDED_VALUE\":float})\n",
    "        Data['Month']=Data.index.month\n",
    "        Data['Year']=Data.index.year\n",
    "    else:\n",
    "        NewData = pd.read_csv('Temp.csv',parse_dates={'datetime':[0]},index_col=['datetime'],\n",
    "                              dtype={\"DATE_PST\":str,\"STATION_NAME\":str,\"EMS_ID\":str,\"PARAMETER\":str,\n",
    "                                     \"INSTRUMENT\":str,\"RAW_VALUE\":float,\"UNIT\":str,\"ROUNDED_VALUE\":float})\n",
    "        NewData['Month']=NewData.index.month\n",
    "        NewData['Year']=NewData.index.year\n",
    "        Data = Data.append(NewData)\n",
    "    return(Data)\n",
    "\n",
    "for species in Species:\n",
    "    print('Downloading '+species)\n",
    "    Data = None    \n",
    "    for year in Years:\n",
    "#         print(year)\n",
    "        Data_Path = \"pub/outgoing/AIR/AnnualSummary/\"\n",
    "        path = Host+Data_Path+year+'/'+species+'.csv'\n",
    "        urllib.request.urlretrieve(path, 'Temp.csv')\n",
    "        Data = ReadFile(Data)\n",
    "#     if Last_Year\n",
    "    \n",
    "    Data_Path = 'pub/outgoing/AIR/Hourly_Raw_Air_Data/Year_to_Date/'\n",
    "    path = Host+Data_Path+species+'.csv'\n",
    "    urllib.request.urlretrieve(path, 'Temp.csv')\n",
    "    Data = ReadFile(Data)\n",
    "    # The datafiles for last year contain a few observations for Jan of the current year, we need to remove those!\n",
    "#     Data = Data.loc[Data['Year']<=Last_Year].copy()\n",
    "    \n",
    "    # Some stations have lots of missing data.  We only want to keep the ones that have at least 50% coverage.\n",
    "    Keep = Data.groupby('EMS_ID').count()['STATION_NAME']\n",
    "    Keep = Keep[Keep>Keep.max()*.5].index\n",
    "    Data = Data.loc[Data['EMS_ID'].isin(Keep)].copy()\n",
    "    \n",
    "    # Agregate data by year and write to a file\n",
    "    AggData = Data.groupby(['EMS_ID','Year']).agg({'RAW_VALUE':'mean'})\n",
    "    Yearly = AggData.unstack()['RAW_VALUE'].to_csv(species+'_Yearly_Averages.csv')\n",
    "    \n",
    "    Data['Year_Month'] = Data['Year']*100+Data['Month']\n",
    "    AggData = Data.groupby(['EMS_ID','Year_Month']).agg({'RAW_VALUE':'mean'})\n",
    "    AggData.unstack()['RAW_VALUE'].to_csv(species+'_Timeseries.csv')\n",
    "    \n",
    "    Last_Year = Data.loc[Data.index.year>2020]\n",
    "\n",
    "    Last_Year=Last_Year.groupby([Last_Year.index,Last_Year.EMS_ID]).mean().unstack()['RAW_VALUE']\n",
    "\n",
    "    Last_Year.to_csv(species+'Mean_Daily_2021_2022.csv')\n",
    "    \n",
    "    print('Completed '+species,': there are ',AggData.unstack().shape[0],' stations available to analyze.')\n",
    "    print()\n",
    "os.remove('Temp.csv')\n",
    "print('Done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sites = pd.read_csv('ftp://ftp.env.gov.bc.ca/pub/outgoing/AIR/Air_Monitoring_Stations/bc_air_monitoring_stations.csv')\n",
    "Sites.to_csv('MonitoringStations.csv')\n",
    "Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
