{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script downloads airquality data from DATABC's ftp server and agregates it by month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CO\n",
      "Retreived 2009\n",
      "Retreived 2010\n",
      "Retreived 2011\n",
      "Retreived 2012\n",
      "Retreived 2013\n",
      "Retreived 2014\n",
      "Retreived 2015\n",
      "Retreived 2016\n",
      "Retreived 2017\n",
      "Completed CO\n",
      "There are  4  stations available to analyze.\n",
      "Downloading H2S\n",
      "Retreived 2009\n",
      "Retreived 2010\n",
      "Retreived 2011\n",
      "Retreived 2012\n",
      "Retreived 2013\n",
      "Retreived 2014\n",
      "Retreived 2015\n",
      "Retreived 2016\n",
      "Retreived 2017\n",
      "Completed H2S\n",
      "There are  3  stations available to analyze.\n",
      "Downloading NO\n",
      "Retreived 2009\n",
      "Retreived 2010\n",
      "Retreived 2011\n",
      "Retreived 2012\n",
      "Retreived 2013\n",
      "Retreived 2014\n",
      "Retreived 2015\n",
      "Retreived 2016\n",
      "Retreived 2017\n",
      "Completed NO\n",
      "There are  53  stations available to analyze.\n",
      "Downloading NO2\n",
      "Retreived 2009\n",
      "Retreived 2010\n",
      "Retreived 2011\n",
      "Retreived 2012\n",
      "Retreived 2013\n",
      "Retreived 2014\n",
      "Retreived 2015\n",
      "Retreived 2016\n",
      "Retreived 2017\n",
      "Completed NO2\n",
      "There are  53  stations available to analyze.\n",
      "Downloading O3\n",
      "Retreived 2009\n",
      "Retreived 2010\n",
      "Retreived 2011\n",
      "Retreived 2012\n",
      "Retreived 2013\n",
      "Retreived 2014\n",
      "Retreived 2015\n",
      "Retreived 2016\n",
      "Retreived 2017\n",
      "Completed O3\n",
      "There are  46  stations available to analyze.\n",
      "Downloading PM10\n",
      "Retreived 2009\n",
      "Retreived 2010\n",
      "Retreived 2011\n",
      "Retreived 2012\n",
      "Retreived 2013\n",
      "Retreived 2014\n",
      "Retreived 2015\n",
      "Retreived 2016\n",
      "Retreived 2017\n",
      "Completed PM10\n",
      "There are  21  stations available to analyze.\n",
      "Downloading PM25\n",
      "Retreived 2009\n",
      "Retreived 2010\n",
      "Retreived 2011\n",
      "Retreived 2012\n",
      "Retreived 2013\n",
      "Retreived 2014\n",
      "Retreived 2015\n",
      "Retreived 2016\n",
      "Retreived 2017\n",
      "Completed PM25\n",
      "There are  66  stations available to analyze.\n",
      "Downloading SO2\n",
      "Retreived 2009\n",
      "Retreived 2010\n",
      "Retreived 2011\n",
      "Retreived 2012\n",
      "Retreived 2013\n",
      "Retreived 2014\n",
      "Retreived 2015\n",
      "Retreived 2016\n",
      "Retreived 2017\n",
      "Completed SO2\n",
      "There are  56  stations available to analyze.\n",
      "Downloading TRS\n",
      "Retreived 2009\n",
      "Retreived 2010\n",
      "Retreived 2011\n",
      "Retreived 2012\n",
      "Retreived 2013\n",
      "Retreived 2014\n",
      "Retreived 2015\n",
      "Retreived 2016\n",
      "Retreived 2017\n",
      "Completed TRS\n",
      "There are  25  stations available to analyze.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request \n",
    "import os\n",
    "\n",
    "Data_Path = \"ftp://ftp.env.gov.bc.ca/pub/outgoing/AIR/AnnualSummary/\"\n",
    "\n",
    "## 2009 is the first year the data is aggregated yearly\n",
    "Years = [str(x) for x in range(2009,2018)]\n",
    "## The gas/particulate data available \n",
    "Species = [\"CO\",\"H2S\",\"NO\",\"NO2\",\"O3\",\"PM10\",\"PM25\",\"SO2\",\"TRS\"]\n",
    "\n",
    "def ReadFile(Data = None):\n",
    "    if Data is None:\n",
    "        Data = pd.read_csv('Temp.csv',parse_dates={'datetime':[0]},index_col=['datetime'],\n",
    "                           dtype={\"DATE_PST\":str,\"STATION_NAME\":str,\"EMS_ID\":str,\n",
    "                                  \"PARAMETER\":str,\"INSTRUMENT\":str,\"RAW_VALUE\":float,\"UNIT\":str,\"ROUNDED_VALUE\":float})\n",
    "        Data['Month']=Data.index.month\n",
    "        Data['Year']=Data.index.year\n",
    "    else:\n",
    "        NewData = pd.read_csv('Temp.csv',parse_dates={'datetime':[0]},index_col=['datetime'],\n",
    "                              dtype={\"DATE_PST\":str,\"STATION_NAME\":str,\"EMS_ID\":str,\n",
    "                                  \"PARAMETER\":str,\"INSTRUMENT\":str,\"RAW_VALUE\":float,\"UNIT\":str,\"ROUNDED_VALUE\":float})\n",
    "        NewData['Month']=NewData.index.month\n",
    "        NewData['Year']=NewData.index.year\n",
    "        Data = Data.append(NewData)\n",
    "    return(Data)\n",
    "\n",
    "for species in Species:\n",
    "    print('Downloading '+species)\n",
    "    Data = None    \n",
    "    for year in Years:\n",
    "        path = Data_Path+Years[-1]+'/'+species+'.csv'\n",
    "        urllib.request.urlretrieve(path, 'Temp.csv')\n",
    "        Data = ReadFile(Data)\n",
    "    # Agregate data by month and write to a file\n",
    "    AggData = Data.groupby(['STATION_NAME','Month']).agg({'RAW_VALUE':'mean'})\n",
    "    AggData.unstack().to_csv(species+'_Monthly_Averages.csv')\n",
    "    # Agregate data by year and write to a file\n",
    "    AggData = Data.groupby(['STATION_NAME','Year']).agg({'RAW_VALUE':'mean'})\n",
    "    AggData.unstack().to_csv(species+'_Yearly_Averages.csv')\n",
    "    print('Completed '+species,': there are ',AggData.unstack().shape[0],' stations available to analyze.')\n",
    "os.remove('Temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 18)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# for DataSet in ['PM25','NOx']:\n",
    "# Data = pd.read_csv('PM25.csv',parse_dates={'datetime':[0]},index_col=['datetime'])\n",
    "\n",
    "print(Yearly.unstack().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9251, 2)\n"
     ]
    }
   ],
   "source": [
    "# level_values = Data.index.get_level_values\n",
    "# print(level_values)\n",
    "# Monthly = Data.groupby(['STATION_NAME']+[pd.Grouper(freq='M', level=0)]).mean()\n",
    "# Station = Data.groupby('STATION_NAME').first()\n",
    "# print(Monthly.shape)#=Monthly.index.levels[1].month.values\n",
    "# for mo in range(1,12):\n",
    "#     print(Monthly.unstack()['datetime'].month)\n",
    "# Monthly['RAW_VALUE'].unstack().plot()\n",
    "# Monthly.reset_index()\n",
    "# Data.to_csv('PM2_5.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
